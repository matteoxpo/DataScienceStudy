{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка к анализу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from scipy.stats import spearmanr\n",
    "%matplotlib inline\n",
    "\n",
    "ALPHA = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные из файла \"heart.csv\" с датасетом, также выведем информацию о данных и посмотрим первые 5 наблюдений из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   age       303 non-null    int64\n",
      " 1   sex       303 non-null    int64\n",
      " 2   cp        303 non-null    int64\n",
      " 3   trestbps  303 non-null    int64\n",
      " 4   chol      303 non-null    int64\n",
      " 5   fbs       303 non-null    int64\n",
      " 6   restecg   303 non-null    int64\n",
      " 7   thalach   303 non-null    int64\n",
      " 8   exang     303 non-null    int64\n",
      " 9   target    303 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 23.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  target\n",
       " 0   63    1   3       145   233    1        0      150      0       1\n",
       " 1   37    1   2       130   250    0        1      187      0       1\n",
       " 2   41    0   1       130   204    0        0      172      0       1\n",
       " 3   56    1   1       120   236    0        1      178      0       1\n",
       " 4   57    0   0       120   354    0        1      163      1       1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('heart.csv')\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "data_info = data.info()\n",
    "data_head = data.head()\n",
    "\n",
    "data_info, data_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **age** — возраст пациента\n",
    "* **sex** — пол пациента (1 = мужчина, 0 = женщина)\n",
    "* **cp** — тип боли в груди (1 = типичная стенокардия, 2 = атипичная стенокардия, 3 = другой вид боли, 4 = нет боли)\n",
    "* **trestbps** — артериальное давление в состоянии покоя (мм ртутного столба, на момент госпитализации)\n",
    "* **chol** — уровень холестерола (мг/дл)\n",
    "* **fbs** — уровень сахара крови натощак выше 120 мг/дл (1 = да, 0 = нет)\n",
    "* **restecg** — результат ЭКГ в состоянии покоя (0 = нормальный, 1 = абнормальный, 2 = признаки гипертрофии желудочка)\n",
    "* **thalach** — максимальная зафиксированная частота сердцебиения\n",
    "* **exang** — стенокардия в результате физической нагружки (1 = да, 0 = нет)\n",
    "* **target** — наличие сердечно-сосудистого заболевания (1 = да, 0 = нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дескриптивный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Был проделан в файле lab1](lab1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стандартизация переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Стандартизация — это процесс приведения числовых признаков (фичей) к единому масштабу. Обычно это делается так, чтобы все переменные имели среднее значение 0 и стандартное отклонение 1. Это достигается путем вычисления z-оценки для каждого значения:  \n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "Где:\n",
    "* $x$ — текущее значение признака,\n",
    "* $\\mu$ — среднее значение признака,\n",
    "* $\\sigma$ — стандартное отклонение признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нужно ли выполнять стандартизацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "Count of uniqeu: 41\n",
      "Values: [63 37 41 56 57 44 52 54 48 49 64 58 50 66 43 69 59 42 61 40 71 51 65 53\n",
      " 46 45 39 47 62 34 35 29 55 60 67 68 74 76 70 38 77]\n",
      "Min = 29 Max = 77\n",
      "--------------------------------------------------\n",
      "sex\n",
      "Count of uniqeu: 2\n",
      "Values: [1 0]\n",
      "Min = 0 Max = 1\n",
      "--------------------------------------------------\n",
      "cp\n",
      "Count of uniqeu: 4\n",
      "Values: [3 2 1 0]\n",
      "Min = 0 Max = 3\n",
      "--------------------------------------------------\n",
      "trestbps\n",
      "Count of uniqeu: 49\n",
      "Values: [145 130 120 140 172 150 110 135 160 105 125 142 155 104 138 128 108 134\n",
      " 122 115 118 100 124  94 112 102 152 101 132 148 178 129 180 136 126 106\n",
      " 156 170 146 117 200 165 174 192 144 123 154 114 164]\n",
      "Min = 94 Max = 200\n",
      "--------------------------------------------------\n",
      "chol\n",
      "Count of uniqeu: 152\n",
      "Values: [233 250 204 236 354 192 294 263 199 168 239 275 266 211 283 219 340 226\n",
      " 247 234 243 302 212 175 417 197 198 177 273 213 304 232 269 360 308 245\n",
      " 208 264 321 325 235 257 216 256 231 141 252 201 222 260 182 303 265 309\n",
      " 186 203 183 220 209 258 227 261 221 205 240 318 298 564 277 214 248 255\n",
      " 207 223 288 160 394 315 246 244 270 195 196 254 126 313 262 215 193 271\n",
      " 268 267 210 295 306 178 242 180 228 149 278 253 342 157 286 229 284 224\n",
      " 206 167 230 335 276 353 225 330 290 172 305 188 282 185 326 274 164 307\n",
      " 249 341 407 217 174 281 289 322 299 300 293 184 409 259 200 327 237 218\n",
      " 319 166 311 169 187 176 241 131]\n",
      "Min = 126 Max = 564\n",
      "--------------------------------------------------\n",
      "fbs\n",
      "Count of uniqeu: 2\n",
      "Values: [1 0]\n",
      "Min = 0 Max = 1\n",
      "--------------------------------------------------\n",
      "restecg\n",
      "Count of uniqeu: 3\n",
      "Values: [0 1 2]\n",
      "Min = 0 Max = 2\n",
      "--------------------------------------------------\n",
      "thalach\n",
      "Count of uniqeu: 91\n",
      "Values: [150 187 172 178 163 148 153 173 162 174 160 139 171 144 158 114 151 161\n",
      " 179 137 157 123 152 168 140 188 125 170 165 142 180 143 182 156 115 149\n",
      " 146 175 186 185 159 130 190 132 147 154 202 166 164 184 122 169 138 111\n",
      " 145 194 131 133 155 167 192 121  96 126 105 181 116 108 129 120 112 128\n",
      " 109 113  99 177 141 136  97 127 103 124  88 195 106  95 117  71 118 134\n",
      "  90]\n",
      "Min = 71 Max = 202\n",
      "--------------------------------------------------\n",
      "exang\n",
      "Count of uniqeu: 2\n",
      "Values: [0 1]\n",
      "Min = 0 Max = 1\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for column in X.columns:\n",
    "    print(column)\n",
    "    print(f\"Count of uniqeu: {len(X[column].unique())}\\nValues: {X[column].unique()}\")\n",
    "    print(f'Min = {X[column].min()} Max = {X[column].max()}')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем выполнять стандартизацию между числовыми переменными:  \n",
    "* age (возраст): числовая переменная с возможным диапазоном от 20 до 80 лет\n",
    "* trestbps (артериальное давление): числовая переменная, диапазон может быть от 90 до 200\n",
    "* chol (уровень холестерина): числовая переменная, диапазон от 100 до 400\n",
    "* thalach (максимальный пульс): числовая переменная, диапазон от 70 до 200  \n",
    "\n",
    "sex, cp, fbs, restecg, exang — это категориальные или бинарные переменные, поэтому стандартизация им не нужна  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952197</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.763956</td>\n",
       "      <td>-0.256334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.915313</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>0.072199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.633471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.474158</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>-0.816773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>-0.198357</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.239897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.290464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.663867</td>\n",
       "      <td>2.082050</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex  cp  trestbps      chol  fbs  restecg   thalach  exang\n",
       "0  0.952197    1   3  0.763956 -0.256334    1        0  0.015443      0\n",
       "1 -1.915313    1   2 -0.092738  0.072199    0        1  1.633471      0\n",
       "2 -1.474158    0   1 -0.092738 -0.816773    0        0  0.977514      0\n",
       "3  0.180175    1   1 -0.663867 -0.198357    0        1  1.239897      0\n",
       "4  0.290464    0   0 -0.663867  2.082050    0        1  0.583939      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_features = ['age', 'trestbps', 'chol', 'thalach']\n",
    "\n",
    "X_scaled = X.copy()\n",
    "\n",
    "X_scaled[numeric_features] = scaler.fit_transform(X_scaled[numeric_features])\n",
    "\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что после стандартизации среднее стало близко к нулю, а среднеквадратичное отклонение приблизительно равно 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_scaled['age']) < 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_scaled['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики для оценки качества классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица путанницы, TP, FN, FP, TN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                       | Предсказанный класс 1 | Предсказанный класс 2 |\n",
    "|-----------------------|-----------------------|-----------------------|\n",
    "| **Фактический класс 1** | True Positive (TP)       | False Negative (FN)     |\n",
    "| **Фактический класс 2** | False Positive (FP)      | True Negative (TN)      |\n",
    "\n",
    "True Positive (TP): Количество правильно классифицированных положительных объектов.  \n",
    "$$\n",
    "TP = \\text{Количество объектов, правильно предсказанных как класс 1}\n",
    "$$\n",
    "\n",
    "False Negative (FN): Количество положительных объектов, неправильно классифицированных как отрицательные.  \n",
    "$$\n",
    "FN = \\text{Количество объектов, фактически класс 1, но предсказанных как класс 2}\n",
    "$$\n",
    "\n",
    "False Positive (FP): Количество отрицательных объектов, неправильно классифицированных как положительные.  \n",
    "$$\n",
    "FP = \\text{Количество объектов, фактически класс 2, но предсказанных как класс 1}\n",
    "$$\n",
    "\n",
    "True Negative (TN): Количество правильно классифицированных отрицательных объектов.  \n",
    "$$\n",
    "TN = \\text{Количество объектов, правильно предсказанных как класс 2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точность, полнота и  среднее гармоническое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Precision (точность):\n",
    "$$\n",
    "Precision =  \\frac{TP}{TP + FP}\n",
    "$$​  \n",
    "Precision показывает, какая доля предсказанных положительных примеров (True Positives, TP) действительно является положительными, из всех, что модель предсказала как положительные. Высокая точность означает, что модель делает мало ложных срабатываний (False Positives, FP).  \n",
    "Высокий precision важен, когда важно минимизировать ложные положительные срабатывания (например, при диагностике редких заболеваний).  \n",
    "\n",
    "* Recall (полнота):\n",
    "$$\n",
    "Recall= \\frac{TP}{TP + FN}\n",
    "​$$  \n",
    "Recall показывает, какая доля реальных положительных примеров была правильно предсказана моделью. То есть, из всех положительных примеров (True Positives + False Negatives, FN) — сколько модель распознала как положительные (TP).  \n",
    "Высокий recall важен, когда нужно минимизировать количество пропущенных положительных случаев (например, пропущенные случаи мошенничества в финансовых транзакциях).  \n",
    "\n",
    "* F1-score:\n",
    "$$\n",
    "F1_{score} = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n",
    "$$  \n",
    "F1-score — это гармоническое среднее между precision и recall. F1 используется для баланса между precision и recall. Он полезен, когда важно учитывать как ложные срабатывания, так и пропуски.  \n",
    "F1-score особенно полезен в задачах с несбалансированными классами, где один из классов встречается намного реже другого.  \n",
    "\n",
    "* Support (поддержка):  \n",
    "\n",
    "Support — это количество реальных наблюдений каждого класса в тестовом наборе. Например, если у вас два класса (0 и 1), support для класса 1 покажет, сколько примеров этого класса есть в реальных данных. Эта метрика помогает понять, как часто встречаются примеры каждого класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор моделей для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   age       303 non-null    int64\n",
      " 1   sex       303 non-null    int64\n",
      " 2   cp        303 non-null    int64\n",
      " 3   trestbps  303 non-null    int64\n",
      " 4   chol      303 non-null    int64\n",
      " 5   fbs       303 non-null    int64\n",
      " 6   restecg   303 non-null    int64\n",
      " 7   thalach   303 non-null    int64\n",
      " 8   exang     303 non-null    int64\n",
      " 9   target    303 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 23.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    165\n",
       "0    138\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения модели запишем основные характеристики датасета:  \n",
    "* Размер датасета: 303 объекта, 10 признаков\n",
    "* Цель классификации: Предсказание бинарного целевого признака (класс 0 или 1).\n",
    "* Структура классов: Целевая переменная сбалансирована (165 объектов класса 1 и 138 объектов класса 0).\n",
    "* Качество данных: Данные качественные без пропусков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбранные модели:  \n",
    "\n",
    "* Случайный лес  \n",
    "Случайный лес — это ансамблевый метод, который работает путем создания множества деревьев решений и объединения их результатов. Может выявлять сложные закономерности в данных. Он устойчив к выбросам и может обрабатывать большое количество признаков.  \n",
    "\n",
    "* Метод опорных векторов (SVM)\n",
    "SVM эффективен для бинарной классификации и хорошо работает с высокоразмерными данными, особенно в случае, если данные разделимы с помощью сложной границы. Метод также хорошо подходит для задач, связанных с классификацией медицинских данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решающее дерево классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest best params:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79        41\n",
      "           1       0.85      0.78      0.81        50\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.81      0.80      0.80        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [20, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train_scaled, y_train)\n",
    "rf_pred_scaled = grid_rf.predict(X_test_scaled)\n",
    "\n",
    "print('Random forest best params:')\n",
    "print(grid_rf.best_params_)\n",
    "print(classification_report(y_test, rf_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector method best params:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.78        41\n",
      "           1       0.81      0.86      0.83        50\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "grid_svc = GridSearchCV(estimator=svc, param_grid=param_grid_svc, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "svc_pred_scaled = grid_svc.predict(X_test_scaled)\n",
    "\n",
    "print('Support vector method best params:')\n",
    "print(grid_rf.best_params_)\n",
    "print(classification_report(y_test, svc_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Задача классификации без стандратизации данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решающее дерево классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68        41\n",
      "           1       0.89      0.32      0.47        50\n",
      "\n",
      "    accuracy                           0.60        91\n",
      "   macro avg       0.71      0.64      0.58        91\n",
      "weighted avg       0.73      0.60      0.57        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "rf_pred = grid_rf.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.78        41\n",
      "           1       0.81      0.86      0.83        50\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=42)\n",
    "\n",
    "grid_svc = GridSearchCV(estimator=svc, param_grid=param_grid_svc, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "svc_pred = grid_svc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79        41\n",
      "           1       0.85      0.78      0.81        50\n",
      "\n",
      "    accuracy                           0.80        91\n",
      "   macro avg       0.80      0.80      0.80        91\n",
      "weighted avg       0.81      0.80      0.80        91\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68        41\n",
      "           1       0.89      0.32      0.47        50\n",
      "\n",
      "    accuracy                           0.60        91\n",
      "   macro avg       0.71      0.64      0.58        91\n",
      "weighted avg       0.73      0.60      0.57        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_pred_scaled))\n",
    "print('-' * 70)\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как показала практика случайный лес сильно зависит от стандартизации данных, процент правильных ответов упал на 20, да и в целом метрики показывают качество ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.78        41\n",
      "           1       0.81      0.86      0.83        50\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.78        41\n",
      "           1       0.81      0.86      0.83        50\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, svc_pred_scaled))\n",
    "print('-' * 70)\n",
    "print(classification_report(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод опорных векторов показал большую устойчивость к нестандартизированным данным"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
