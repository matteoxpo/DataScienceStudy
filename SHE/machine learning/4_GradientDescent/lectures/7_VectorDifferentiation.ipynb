{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторное дифференцирование "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "f(x): R^n \\rightarrow R\n",
    "$  \n",
    "где x - вектор  \n",
    "$  \n",
    "\\bigtriangledown_x f(x): (\\frac{\\delta f(x)}{\\delta x_1}, \\frac{\\delta f(x)}{\\delta x_2}, ..., \\frac{\\delta f(x)}{\\delta x_n})^T\n",
    "$  \n",
    "Пусть есть вектор:  \n",
    "$\n",
    "f(x) = a^t \\times x\n",
    "$  \n",
    "a - вектор параметров  \n",
    "x - вектор переменных  \n",
    "$  \n",
    "\\bigtriangledown_x f(x) = ?\n",
    "$  \n",
    "Распишем i-ю компоненту вектора производной  \n",
    "$\n",
    "\\frac{\\delta f(x)}{\\delta x_j} = \\frac{\\delta(a_1 \\ times x_1 + a_2 \\times x_2 + ... + a_n \\times x_n)}{\\delta x_j} = a_j\n",
    "$\n",
    "То есть градиент от такой функции будет вектор производных, а именно вектор параметров, так как каждая j-я компонента равна $a_j$  \n",
    "$\n",
    "\\bigtriangledown_x a^T \\times x = a\n",
    "$  \n",
    "Рассмотрим еще один пример  \n",
    "Пусть матрица  \n",
    "$\n",
    "A_{n \\times n} \n",
    "$  \n",
    "И есть функция:  \n",
    "$\n",
    "f(x) = x^T \\times A \\times x  \n",
    "$  \n",
    "Ищем градиент $\\bigtriangledown_x (x^T \\times A \\times x)$:  \n",
    "Для начала разверем нашу фунцию как сумму  \n",
    "$\n",
    "f(x) = x^T \\times A \\times x = \\sum_{i,j} x_i a_{ij} x_j\n",
    "$  \n",
    "где $x_i$ и $x_j$ - компоненты вектора $x$, а $a_{ij}$ - компоненты вектора $A$  \n",
    "Также распишем i-ю компоненту производной  \n",
    "## Метод с лекции с множеством пропусков и непонятностей  \n",
    "$  \\newline\n",
    "\\frac{\\delta f(x)}{\\delta x_i} = \\frac{\\delta}{\\delta x_i} \\times \\sum_j x_j \\times (A \\times x)_j \n",
    "\\newline\n",
    "= \\frac{\\delta}{\\delta x_i} \\sum_j x_j \\times (\\sum_k a_{jk} \\times x_k) \n",
    "\\newline\n",
    "= \\frac{\\delta}{\\delta x_i} \\sum_{j,k} x_j \\times x_k \\times a_{jk} \n",
    "\\newline\n",
    "= \\sum_{j \\neq i} a_{ji} \\times x_j + \\sum_{k \\neq j} a_{ik} \\times x_k + 2 \\times a_{ii} \\times x_i \n",
    "\\newline\n",
    "= \\sum_j a_{ji} \\times x_j + \\sum_k a_{ik} \\times x_k \n",
    "\\newline\n",
    "= \\sum_j (a_{ji} + a_{ij}) \\times x_j \n",
    "$  \n",
    "$\n",
    "\\bigtriangledown_x (x^T \\times A \\times x) = (A + A^T)\\times x\n",
    "$\n",
    "\n",
    "## Более расписанный метод  \n",
    "Градиент - вектор частных производных по всем компонентам  \n",
    "$\n",
    "(\\bigtriangledown_x f(x))_i = \\frac{\\delta f(x)}{\\delta x_i}\n",
    "$  \n",
    "Производная по $x_i$  \n",
    "$\n",
    "\\frac{\\delta f(x)}{\\delta x_i} = \\frac{\\delta}{\\delta x_i} \\sum_{j,k} x_j a_jk x_k  \n",
    "$  \n",
    "Раскроем сумму, ведь кф-ы из матрицы $A$ - просто константы   \n",
    "$\n",
    "\\frac{\\delta f(x)}{\\delta x_i} = \\sum_{j,k} a_{jk} \\frac{\\delta}{\\delta x_i} (x_j x_k) \n",
    "$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно разложить производную от $a_j a_k$:  \n",
    "- Если $j \\neq i$,но $k \\neq i$, то производная равна $0$\n",
    "- Если $i = j$,но $k = i$, то производная равна $2x_i$\n",
    "- Если $j = i$,но $k \\neq i$, то производная равна $x_k$\n",
    "- Если $k = i$,но $j \\neq i$, то производная равна $x_j$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсюда следует:  \n",
    "$\n",
    "\\frac{\\delta f(x)}{\\delta x_i} = 2 a_{ii} x_i + \\sum_{j \\neq i} a_{ji} x_j + \\sum_{k \\neq i} a_{ik} x_k\n",
    "$  \n",
    "Теперь понимаем, что сумму можно объеденить, так как она симметрична с одной и с другой стороны $a_{ji}$ и $a_{ij}$:  \n",
    "$\n",
    "\\bigtriangledown_x (x^T \\times A \\times x) = (A + A^T)\\times x\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
