{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snxSUWXD7q_p"
      },
      "source": [
        "## Домашнее задание по неделе 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-8OLsAV7wrQ"
      },
      "source": [
        "Как было рассказано на лекции, стохастический градиентый спуск сходится быстрее, чем полный, хотя и менее стабильно. В этом задании вам предлагается реализовать стохастический градиентный спуск и сравнить его с точным вычислением весов линейной модели по скорости работы и значению метрики качества."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IgQyWw5o7Nej"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGD1wQgMruJw"
      },
      "source": [
        "### Задание 0\n",
        "\n",
        "Реализуйте класс ```LinearRegressionSGD``` c обучением и и применением линейной регрессии, построенной с помощью стохастического градиентного спуска, с заданным интерфейсом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "QZxdV27R9-uc"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class LinearRegressionSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-4, max_steps=100, w0=None, alpha=1e-4, batch_size=1):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов\n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.batch_size = batch_size\n",
        "        self.w_history = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        l, d = X.shape\n",
        "        if self.w0 is None:\n",
        "          self.w0 = np.random.rand(d)\n",
        "          print(self.w0)\n",
        "\n",
        "        self.w = self.w0\n",
        "        w_new = 0\n",
        "        for step in range(self.max_steps):\n",
        "          self.w_history.append(self.w)\n",
        "          indices = np.random.choice(l, self.batch_size, replace=False)\n",
        "          X_batch = X.iloc[indices]\n",
        "          y_batch = y.iloc[indices]\n",
        "          w_new = self.w - self.alpha * self.calc_gradient(X_batch, y_batch)\n",
        "          if (np.linalg.norm(w_new - self.w) < self.epsilon):\n",
        "            break\n",
        "\n",
        "          self.w = w_new\n",
        "        if (np.linalg.norm(w_new - self.w) < self.epsilon):\n",
        "          print(\"Breaked because of diff wath less then epsilon\")\n",
        "        else:\n",
        "          print(\"Breaked because of steps wath more then we can do\")\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        ---\n",
        "        output: np.array (l)\n",
        "        \"\"\"\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "\n",
        "        return np.dot(X, self.w)\n",
        "\n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: np.array (d)\n",
        "        \"\"\"\n",
        "\n",
        "        l, d = X.shape\n",
        "        return (2/l) * np.dot(X.T,(np.dot(X, self.w) - y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNOm9-bXpdT3"
      },
      "source": [
        "Проверять работу мы будем на имеющемся в sklearn наборе данных.\n",
        "Возьмем стандартный [датасет](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) со стоимостью жилья в различных районах Калифорнии в 1990 году.  Датасет содержит информацию о средних ценах на жилье в районе и какие-то параметры района: средний возраст домов, среднее число комнат, население"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c24JCwes9-pe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5R-G_B8HJMtn",
        "outputId": "59de3e73-9929-4d0f-d354-beaf45c59065"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17853</th>\n",
              "      <td>5.3994</td>\n",
              "      <td>23.0</td>\n",
              "      <td>5.019157</td>\n",
              "      <td>1.022989</td>\n",
              "      <td>910.0</td>\n",
              "      <td>3.486590</td>\n",
              "      <td>37.44</td>\n",
              "      <td>-121.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15963</th>\n",
              "      <td>3.9567</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.173664</td>\n",
              "      <td>1.127863</td>\n",
              "      <td>1848.0</td>\n",
              "      <td>3.526718</td>\n",
              "      <td>37.71</td>\n",
              "      <td>-122.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20106</th>\n",
              "      <td>3.0500</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5.383764</td>\n",
              "      <td>1.095941</td>\n",
              "      <td>753.0</td>\n",
              "      <td>2.778598</td>\n",
              "      <td>37.94</td>\n",
              "      <td>-120.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15525</th>\n",
              "      <td>2.2500</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4.331113</td>\n",
              "      <td>1.109420</td>\n",
              "      <td>2737.0</td>\n",
              "      <td>2.604186</td>\n",
              "      <td>33.14</td>\n",
              "      <td>-117.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5234</th>\n",
              "      <td>2.0187</td>\n",
              "      <td>39.0</td>\n",
              "      <td>4.876068</td>\n",
              "      <td>1.102564</td>\n",
              "      <td>1313.0</td>\n",
              "      <td>5.611111</td>\n",
              "      <td>33.94</td>\n",
              "      <td>-118.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "17853  5.3994      23.0  5.019157   1.022989       910.0  3.486590     37.44   \n",
              "15963  3.9567      52.0  5.173664   1.127863      1848.0  3.526718     37.71   \n",
              "20106  3.0500      17.0  5.383764   1.095941       753.0  2.778598     37.94   \n",
              "15525  2.2500      16.0  4.331113   1.109420      2737.0  2.604186     33.14   \n",
              "5234   2.0187      39.0  4.876068   1.102564      1313.0  5.611111     33.94   \n",
              "\n",
              "       Longitude  \n",
              "17853    -121.88  \n",
              "15963    -122.44  \n",
              "20106    -120.29  \n",
              "15525    -117.05  \n",
              "5234     -118.23  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eIJwWnInXnr"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Метрикой качества в нашей задаче будет MAPE - Mean Absolute Percentage Error. Реализуйте её с заданным интефейсом и вычислите\n",
        "```MAPE(y_test, y_0)```, где ```y_0 = (mean(y_test), mean(y_test), ...)```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "znoDavxyuLsi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def MAPE(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    y_true: np.array (l) - истинные значения\n",
        "    y_pred: np.array (l) - предсказанные значения\n",
        "    ---\n",
        "    output: float [0, +inf) - средняя абсолютная процентная ошибка\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.abs((y_true - y_pred) / y_true).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "e6mTAykeojwp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "62.2"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_0 = np.full_like(y_test, np.mean(y_test))\n",
        "\n",
        "np.round(MAPE(y_test, y_0) * 100, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nNy2ITxuMKf"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "Обучите ```LinearRegressionSGD``` с базовыми параметрами на тренировочном наборе данных (```X_train```, ```y_train```), сделайте предсказание на тестовых данных ```X_test```, записав результат в переменную ```y_pred_sgd```  и вычислите ошибку MAPE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7BIHwAwUvB-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.15026141 0.57633841 0.36305149 0.15266238 0.99353665 0.58360663\n",
            " 0.3608084  0.25723578]\n",
            "Breaked because of diff wath less then epsilon\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([1.10851052e+235, 4.94831447e+235, 5.03787227e+235, ...,\n",
              "       3.61886111e+235, 1.99705356e+235, 2.65038574e+235])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sgd = LinearRegressionSGD()\n",
        "\n",
        "y_pred_sgd = sgd.fit(X_train, y_train).predict(X_test)\n",
        "y_pred_sgd\n",
        "# y_train\n",
        "# MAPE(y_test, y_pred_sgd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWappMdMtIPV"
      },
      "source": [
        "### Задание 3\n",
        "\n",
        "Вычислите веса по точной формуле, используя ```X_train``` и ```y_train```; предскажите с их помощью целевую переменную на ```X_test```, записав результат в переменную ```y_pred_lr``` и вычислите ошибку MAPE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjMUlPje9-k0"
      },
      "outputs": [],
      "source": [
        "## y_pred_lr = ...\n",
        "\n",
        "MAPE(y_test, y_pred_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL9L-4cwxZho"
      },
      "source": [
        "## Бонусное задание по неделе 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZFaUn7yx04u"
      },
      "source": [
        "До этого вы релизовывали модели, в которых не было штрафа за величину весов ```w```. Как было рассказано ранее в лекциях, это может привести к неустойчивости модели и переобучению. Чтобы избежать этих эффектов, предлагается добавить к оптимизируемому функционалу L2-норму весов; таким образом, будем решать задачу гребневой регрессии, Ridge:\n",
        "\n",
        "$$ \\frac{1}{l}(Xw-y)^T(Xw-y) +\\gamma||w||_2 \\rightarrow \\min_{w}. $$\n",
        "\n",
        "### Задание 11\n",
        "Реализуйте обучение такой модели в матричном виде (смотрите дополнительные материалы к этой неделе) с помощью стохастического градиентного спуска. Класс должен совпадать по набору реализованных функций с ```LinearRegressionVectorized```, разница будет лишь в параметре $\\gamma$, отвечающем за степень регуляризации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEXqBqmGxWDz"
      },
      "outputs": [],
      "source": [
        "class RidgeSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-4, max_steps=1000, w0=None, alpha=1e-2, gamma=0):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов\n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        gamma: коэффициент регуляризации\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.w = None\n",
        "        self.w_history = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        ---\n",
        "        output: np.array (l)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: np.array (d)\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t9rqXFu8Pq6"
      },
      "source": [
        "Так же, как и в основном задании, обучите модель с базовыми параметрами на тренировочных данных и сделайте прогноз y_pred_ridge. Выведите значение MAPE(y_test, y_pred_ridge)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A2hak_A8QPO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
