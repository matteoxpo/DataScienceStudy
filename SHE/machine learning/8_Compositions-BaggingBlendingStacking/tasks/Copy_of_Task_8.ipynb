{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP103Mzpjnge"
      },
      "source": [
        "1. Загрузите данные load_wine из sklearn.datasets. Из обучающей части исключите объекты класса 2. Обучите случайный лес, задав только гиперпараметры `n_estimators=100` и `random_state=0`. Оцените важность признаков. Укажите название двух наиболее важных признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ksz6uSlzjdXD"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "data = load_wine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 178\n",
            ":Number of Attributes: 13 numeric, predictive attributes and the class\n",
            ":Attribute Information:\n",
            "    - Alcohol\n",
            "    - Malic acid\n",
            "    - Ash\n",
            "    - Alcalinity of ash\n",
            "    - Magnesium\n",
            "    - Total phenols\n",
            "    - Flavanoids\n",
            "    - Nonflavanoid phenols\n",
            "    - Proanthocyanins\n",
            "    - Color intensity\n",
            "    - Hue\n",
            "    - OD280/OD315 of diluted wines\n",
            "    - Proline\n",
            "    - class:\n",
            "        - class_0\n",
            "        - class_1\n",
            "        - class_2\n",
            "\n",
            ":Summary Statistics:\n",
            "\n",
            "============================= ==== ===== ======= =====\n",
            "                                Min   Max   Mean     SD\n",
            "============================= ==== ===== ======= =====\n",
            "Alcohol:                      11.0  14.8    13.0   0.8\n",
            "Malic Acid:                   0.74  5.80    2.34  1.12\n",
            "Ash:                          1.36  3.23    2.36  0.27\n",
            "Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
            "Magnesium:                    70.0 162.0    99.7  14.3\n",
            "Total Phenols:                0.98  3.88    2.29  0.63\n",
            "Flavanoids:                   0.34  5.08    2.03  1.00\n",
            "Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
            "Proanthocyanins:              0.41  3.58    1.59  0.57\n",
            "Colour Intensity:              1.3  13.0     5.1   2.3\n",
            "Hue:                          0.48  1.71    0.96  0.23\n",
            "OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
            "Proline:                       278  1680     746   315\n",
            "============================= ==== ===== ======= =====\n",
            "\n",
            ":Missing Attribute Values: None\n",
            ":Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
            ":Creator: R.A. Fisher\n",
            ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            ":Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML Wine recognition datasets.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "\n",
            "The data is the results of a chemical analysis of wines grown in the same\n",
            "region in Italy by three different cultivators. There are thirteen different\n",
            "measurements taken for different constituents found in the three types of\n",
            "wine.\n",
            "\n",
            "Original Owners:\n",
            "\n",
            "Forina, M. et al, PARVUS -\n",
            "An Extendible Package for Data Exploration, Classification and Correlation.\n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science.\n",
            "\n",
            ".. dropdown:: References\n",
            "\n",
            "    (1) S. Aeberhard, D. Coomans and O. de Vel,\n",
            "    Comparison of Classifiers in High Dimensional Settings,\n",
            "    Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\n",
            "    Mathematics and Statistics, James Cook University of North Queensland.\n",
            "    (Also submitted to Technometrics).\n",
            "\n",
            "    The data was used with many others for comparing various\n",
            "    classifiers. The classes are separable, though only RDA\n",
            "    has achieved 100% correct classification.\n",
            "    (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\n",
            "    (All results using the leave-one-out technique)\n",
            "\n",
            "    (2) S. Aeberhard, D. Coomans and O. de Vel,\n",
            "    \"THE CLASSIFICATION PERFORMANCE OF RDA\"\n",
            "    Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\n",
            "    Mathematics and Statistics, James Cook University of North Queensland.\n",
            "    (Also submitted to Journal of Chemometrics).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(data['DESCR'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
              "       3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
              "       1.065e+03])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  \n",
              "0                            3.92   1065.0  \n",
              "1                            3.40   1050.0  \n",
              "2                            3.17   1185.0  \n",
              "3                            3.45   1480.0  \n",
              "4                            2.93    735.0  \n",
              "..                            ...      ...  \n",
              "173                          1.74    740.0  \n",
              "174                          1.56    750.0  \n",
              "175                          1.56    835.0  \n",
              "176                          1.62    840.0  \n",
              "177                          1.60    560.0  \n",
              "\n",
              "[178 rows x 13 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wine = pd.DataFrame(data= np.c_[data['data']],\n",
        "                     columns= data['feature_names'])\n",
        "wine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "173    2\n",
              "174    2\n",
              "175    2\n",
              "176    2\n",
              "177    2\n",
              "Length: 178, dtype: int64"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wine_target = pd.Series(data =  data['target'])\n",
        "wine_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "125    1\n",
              "126    1\n",
              "127    1\n",
              "128    1\n",
              "129    1\n",
              "Length: 130, dtype: int64"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filter_index = (wine_target!= 2)\n",
        "wine_target_filterd = wine_target.loc[filter_index]\n",
        "wine_target_filterd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>12.07</td>\n",
              "      <td>2.16</td>\n",
              "      <td>2.17</td>\n",
              "      <td>21.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.65</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.28</td>\n",
              "      <td>378.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>12.43</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.29</td>\n",
              "      <td>21.5</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.77</td>\n",
              "      <td>3.94</td>\n",
              "      <td>0.69</td>\n",
              "      <td>2.84</td>\n",
              "      <td>352.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>11.79</td>\n",
              "      <td>2.13</td>\n",
              "      <td>2.78</td>\n",
              "      <td>28.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>2.13</td>\n",
              "      <td>2.24</td>\n",
              "      <td>0.58</td>\n",
              "      <td>1.76</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.97</td>\n",
              "      <td>2.44</td>\n",
              "      <td>466.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>12.37</td>\n",
              "      <td>1.63</td>\n",
              "      <td>2.30</td>\n",
              "      <td>24.5</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.22</td>\n",
              "      <td>2.45</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.90</td>\n",
              "      <td>2.12</td>\n",
              "      <td>0.89</td>\n",
              "      <td>2.78</td>\n",
              "      <td>342.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>12.04</td>\n",
              "      <td>4.30</td>\n",
              "      <td>2.38</td>\n",
              "      <td>22.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>2.10</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.79</td>\n",
              "      <td>2.57</td>\n",
              "      <td>580.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "125    12.07        2.16  2.17               21.0       85.0           2.60   \n",
              "126    12.43        1.53  2.29               21.5       86.0           2.74   \n",
              "127    11.79        2.13  2.78               28.5       92.0           2.13   \n",
              "128    12.37        1.63  2.30               24.5       88.0           2.22   \n",
              "129    12.04        4.30  2.38               22.0       80.0           2.10   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "125        2.65                  0.37             1.35             2.76  0.86   \n",
              "126        3.15                  0.39             1.77             3.94  0.69   \n",
              "127        2.24                  0.58             1.76             3.00  0.97   \n",
              "128        2.45                  0.40             1.90             2.12  0.89   \n",
              "129        1.75                  0.42             1.35             2.60  0.79   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  \n",
              "0                            3.92   1065.0  \n",
              "1                            3.40   1050.0  \n",
              "2                            3.17   1185.0  \n",
              "3                            3.45   1480.0  \n",
              "4                            2.93    735.0  \n",
              "..                            ...      ...  \n",
              "125                          3.28    378.0  \n",
              "126                          2.84    352.0  \n",
              "127                          2.44    466.0  \n",
              "128                          2.78    342.0  \n",
              "129                          2.57    580.0  \n",
              "\n",
              "[130 rows x 13 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wine_filtered = wine.loc[filter_index]\n",
        "wine_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=0).fit(wine_filtered, wine_target_filterd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         feature  importance\n",
            "12                       proline    0.298094\n",
            "0                        alcohol    0.216588\n",
            "9                color_intensity    0.191830\n",
            "6                     flavanoids    0.096270\n",
            "4                      magnesium    0.065010\n",
            "3              alcalinity_of_ash    0.029383\n",
            "5                  total_phenols    0.028665\n",
            "1                     malic_acid    0.022743\n",
            "2                            ash    0.014751\n",
            "11  od280/od315_of_diluted_wines    0.010124\n",
            "7           nonflavanoid_phenols    0.010090\n",
            "8                proanthocyanins    0.009384\n",
            "10                           hue    0.007067\n"
          ]
        }
      ],
      "source": [
        "feature_importances = random_forest.feature_importances_\n",
        "\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'feature': wine.columns,\n",
        "    'importance': feature_importances\n",
        "})\n",
        "\n",
        "top_features = feature_importances_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(top_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         feature  importance\n",
            "12                       proline    0.298094\n",
            "0                        alcohol    0.216588\n",
            "9                color_intensity    0.191830\n",
            "6                     flavanoids    0.096270\n",
            "4                      magnesium    0.065010\n",
            "3              alcalinity_of_ash    0.029383\n",
            "5                  total_phenols    0.028665\n",
            "1                     malic_acid    0.022743\n",
            "2                            ash    0.014751\n",
            "11  od280/od315_of_diluted_wines    0.010124\n",
            "7           nonflavanoid_phenols    0.010090\n",
            "8                proanthocyanins    0.009384\n",
            "10                           hue    0.007067\n"
          ]
        }
      ],
      "source": [
        "wine_raw = load_wine()\n",
        "X, y = wine_raw.data, wine_raw.target\n",
        "\n",
        "mask = y != 2\n",
        "X_filtered, y_filtered = X[mask], y[mask]\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(X_filtered, y_filtered)\n",
        "\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'feature': wine_raw.feature_names,\n",
        "    'importance': feature_importances\n",
        "})\n",
        "\n",
        "top_features = feature_importances_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(top_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3_T1dkjkHtg"
      },
      "source": [
        "2. Загрузите данные load_wine из sklearn.datasets. Из обучающей части исключите объекты класса 2. Отмасштабируйте признаки, используя класс StandardScaler с гиперпараметрами по умолчанию. Обучите случайный лес, задав только гиперпараметры  `n_estimators = 100` и `random_state=0`. Оцените важность признаков. Укажите название двух наиболее важных признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "0yQfA9lUkOLg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_scaled = scaler.fit_transform(X_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         feature  importance\n",
            "12                       proline    0.298094\n",
            "0                        alcohol    0.216588\n",
            "9                color_intensity    0.191830\n",
            "6                     flavanoids    0.096270\n",
            "4                      magnesium    0.065010\n",
            "3              alcalinity_of_ash    0.029383\n",
            "5                  total_phenols    0.028665\n",
            "1                     malic_acid    0.022743\n",
            "2                            ash    0.014751\n",
            "11  od280/od315_of_diluted_wines    0.010124\n",
            "7           nonflavanoid_phenols    0.010090\n",
            "8                proanthocyanins    0.009384\n",
            "10                           hue    0.007067\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(X_scaled, y_filtered)\n",
        "\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "feature_importances_df = pd.DataFrame({\n",
        "    'feature': wine_raw.feature_names,\n",
        "    'importance': feature_importances\n",
        "})\n",
        "\n",
        "top_features = feature_importances_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(top_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30upVFxqjtII"
      },
      "source": [
        "Ниже приведена неполная реализация класса Bagging который имеет методы `fit` для обучения бэггинга над `DecisionTreeRegressor` и метод `predict` для предсказания. Допишите необходимый код, чтобы реализовать бэггинг."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hLyrAJW2ntE"
      },
      "source": [
        "используемы переменные в коде:\n",
        "- `self.n_estimators`, `n_estimators` - число используемых деревьев\n",
        "- `self.regressors` - список объектов класса `DecisionTreeRegressor`, к которым уже был применён метод `fit`\n",
        "Данный список необъодимо заполнить в методе `fit` и использовать для предсказания в методе `predict`\n",
        "- `ind`-  выбранные индексы объектов при бутстрапе\n",
        "\n",
        "при создании объекта класса `DecisionTreeRegressor` зафиксируйте  \n",
        "`random_state=0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "q6jU2AoCkmZQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "class Bagging():\n",
        "  def __init__(self, n_estimators=10):\n",
        "    self.n_estimators = n_estimators\n",
        "    self.regressors = []\n",
        "  def fit(self, x_train, y_train):\n",
        "    for i in range(self.n_estimators):\n",
        "      np.random.seed(i)\n",
        "      ind = np.random.choice(np.arange(x_train.shape[0]), size = x_train.shape[0])\n",
        "      self.regressors.append(DecisionTreeRegressor().fit(x_train.iloc[ind], y_train.iloc[ind])) \n",
        "  def predict(self, x_test):\n",
        "    answers = []\n",
        "    for regressor in self.regressors:\n",
        "      answers.append(regressor.predict(x_test))\n",
        "    return np.mean(answers, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d3O4PEdkgWL"
      },
      "source": [
        "Загрузите данные приложенные к заданию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.510632</td>\n",
              "      <td>-1.313935</td>\n",
              "      <td>-0.114209</td>\n",
              "      <td>-0.143679</td>\n",
              "      <td>2.107414</td>\n",
              "      <td>1.507354</td>\n",
              "      <td>-0.315861</td>\n",
              "      <td>-1.030258</td>\n",
              "      <td>0.644616</td>\n",
              "      <td>0.531194</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.892854</td>\n",
              "      <td>-0.699436</td>\n",
              "      <td>0.442937</td>\n",
              "      <td>1.134091</td>\n",
              "      <td>-0.355533</td>\n",
              "      <td>-1.355772</td>\n",
              "      <td>0.363396</td>\n",
              "      <td>1.294192</td>\n",
              "      <td>0.750299</td>\n",
              "      <td>-37.192781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.538866</td>\n",
              "      <td>0.387687</td>\n",
              "      <td>-1.137239</td>\n",
              "      <td>-1.092431</td>\n",
              "      <td>0.038607</td>\n",
              "      <td>1.142312</td>\n",
              "      <td>-0.321904</td>\n",
              "      <td>-0.237227</td>\n",
              "      <td>-1.451496</td>\n",
              "      <td>-0.385336</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056560</td>\n",
              "      <td>1.248607</td>\n",
              "      <td>-0.346863</td>\n",
              "      <td>-0.973055</td>\n",
              "      <td>1.042978</td>\n",
              "      <td>-0.404316</td>\n",
              "      <td>0.028007</td>\n",
              "      <td>-2.658630</td>\n",
              "      <td>-2.001785</td>\n",
              "      <td>-220.464123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.068804</td>\n",
              "      <td>0.776603</td>\n",
              "      <td>-1.611731</td>\n",
              "      <td>-1.239927</td>\n",
              "      <td>0.712057</td>\n",
              "      <td>2.075371</td>\n",
              "      <td>-1.462034</td>\n",
              "      <td>1.151911</td>\n",
              "      <td>1.269848</td>\n",
              "      <td>0.725593</td>\n",
              "      <td>...</td>\n",
              "      <td>1.989607</td>\n",
              "      <td>-0.021897</td>\n",
              "      <td>-0.372160</td>\n",
              "      <td>-0.870986</td>\n",
              "      <td>1.192751</td>\n",
              "      <td>-0.062865</td>\n",
              "      <td>0.209232</td>\n",
              "      <td>-0.350511</td>\n",
              "      <td>0.409299</td>\n",
              "      <td>-325.380249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.884799</td>\n",
              "      <td>-0.620779</td>\n",
              "      <td>0.841720</td>\n",
              "      <td>-1.129511</td>\n",
              "      <td>-0.966720</td>\n",
              "      <td>-1.577867</td>\n",
              "      <td>0.058787</td>\n",
              "      <td>0.223962</td>\n",
              "      <td>-1.005101</td>\n",
              "      <td>0.113334</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214109</td>\n",
              "      <td>-1.083825</td>\n",
              "      <td>-0.476753</td>\n",
              "      <td>-0.904678</td>\n",
              "      <td>-0.637636</td>\n",
              "      <td>-0.741085</td>\n",
              "      <td>-0.126770</td>\n",
              "      <td>-1.063897</td>\n",
              "      <td>-0.003012</td>\n",
              "      <td>-126.861161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.701277</td>\n",
              "      <td>0.614840</td>\n",
              "      <td>0.434146</td>\n",
              "      <td>-0.126249</td>\n",
              "      <td>-0.591696</td>\n",
              "      <td>0.500336</td>\n",
              "      <td>1.018807</td>\n",
              "      <td>0.848046</td>\n",
              "      <td>-0.817596</td>\n",
              "      <td>-0.060330</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.257656</td>\n",
              "      <td>-1.565868</td>\n",
              "      <td>0.049286</td>\n",
              "      <td>0.239042</td>\n",
              "      <td>-1.047043</td>\n",
              "      <td>0.191627</td>\n",
              "      <td>0.071640</td>\n",
              "      <td>0.766967</td>\n",
              "      <td>1.570351</td>\n",
              "      <td>92.835567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0  0.510632 -1.313935 -0.114209 -0.143679  2.107414  1.507354 -0.315861   \n",
              "1  0.538866  0.387687 -1.137239 -1.092431  0.038607  1.142312 -0.321904   \n",
              "2 -0.068804  0.776603 -1.611731 -1.239927  0.712057  2.075371 -1.462034   \n",
              "3 -0.884799 -0.620779  0.841720 -1.129511 -0.966720 -1.577867  0.058787   \n",
              "4 -0.701277  0.614840  0.434146 -0.126249 -0.591696  0.500336  1.018807   \n",
              "\n",
              "        7         8         9    ...       91        92        93        94   \\\n",
              "0 -1.030258  0.644616  0.531194  ... -0.892854 -0.699436  0.442937  1.134091   \n",
              "1 -0.237227 -1.451496 -0.385336  ... -0.056560  1.248607 -0.346863 -0.973055   \n",
              "2  1.151911  1.269848  0.725593  ...  1.989607 -0.021897 -0.372160 -0.870986   \n",
              "3  0.223962 -1.005101  0.113334  ...  0.214109 -1.083825 -0.476753 -0.904678   \n",
              "4  0.848046 -0.817596 -0.060330  ... -0.257656 -1.565868  0.049286  0.239042   \n",
              "\n",
              "        95        96        97        98        99          100  \n",
              "0 -0.355533 -1.355772  0.363396  1.294192  0.750299  -37.192781  \n",
              "1  1.042978 -0.404316  0.028007 -2.658630 -2.001785 -220.464123  \n",
              "2  1.192751 -0.062865  0.209232 -0.350511  0.409299 -325.380249  \n",
              "3 -0.637636 -0.741085 -0.126770 -1.063897 -0.003012 -126.861161  \n",
              "4 -1.047043  0.191627  0.071640  0.766967  1.570351   92.835567  \n",
              "\n",
              "[5 rows x 101 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data = pd.read_csv('data.csv', header=None)\n",
        "Data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nqAF3xSxINs"
      },
      "source": [
        "Положим матрицу объекты-признаки в переменную `X`, а ответы в переменную `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Gme29o-QxXpW"
      },
      "outputs": [],
      "source": [
        "X, y = Data.iloc[:, :100], Data.iloc[:, 100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9Vzjd9uk1rc"
      },
      "source": [
        "\n",
        "Положим первые 6000 объектов в обучающую часть, остальные объекты в тестовую часть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "EgUzGnlvk2st"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = X[:6000], y[:6000]\n",
        "x_test, y_test = X[6000:], y[6000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9wrsEQk9BU"
      },
      "source": [
        "3. Обучите бэггинг на 1 дереве. Оцените качество по метрике MSE на тестовой части. Ответ разделите на 1000 и округлите до целой части по математичестким правилам округления."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "lx5XJC3Sk8NS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(34.0655)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bagging = Bagging(n_estimators=1)\n",
        "bagging.fit(x_train, y_train)\n",
        "y_pred = bagging.predict(x_test)\n",
        "round(mean_squared_error(y_test, y_pred) / 1000,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRmiSEn8lEju"
      },
      "source": [
        "4. Обучите бэггинг на 5 деревьях. Оцените качество по метрике MSE на тестовой части. Ответ разделите на 1000 и округлите до целой части по математичестким правилам округления."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "4gOA8WLJlPuO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(14.85)"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bagging = Bagging(n_estimators=5)\n",
        "bagging.fit(x_train, y_train)\n",
        "y_pred = bagging.predict(x_test)\n",
        "round(mean_squared_error(y_test, y_pred) / 1000,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzXNbEBblQgn"
      },
      "source": [
        "5. Обучите бэггинг на 100 деревьях. Оцените качество по метрике MSE на тестовой части. . Ответ разделите на 1000 и округлите до целой части по математичестким правилам округления."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "B3zKondflUpQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(11.03)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bagging = Bagging(n_estimators=100)\n",
        "bagging.fit(x_train, y_train)\n",
        "y_pred = bagging.predict(x_test)\n",
        "round(mean_squared_error(y_test, y_pred) / 1000,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U70oTX93lZfH"
      },
      "source": [
        "6. Обучите на этих же данных случайный лес, используйте гиперпараметр `n_estimators = 1`, зафиксируйте  \n",
        "`random_state=0`. Оцените качество по метрике MSE на тестовой части. . Ответ разделите на 1000 и округлите до целой части по математичестким правилам округления."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "EuQorK1ald7U"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(35.11)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree = RandomForestRegressor(n_estimators=1, random_state=0).fit(x_train, y_train)\n",
        "y_pred = tree.predict(x_test)\n",
        "round(mean_squared_error(y_test, y_pred) / 1000,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ehRS_oXly8P"
      },
      "source": [
        "7. Обучите на этих же данных случайный лес, используйте гиперпараметр `n_estimators = 5`, зафиксируйте  \n",
        "`random_state=0`. Оцените качество по метрике MSE на тестовой части. . Ответ разделите на 1000 и округлите до целой части по математичестким правилам округления."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "6KQS5Hkfl9Wn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(15.43)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree = RandomForestRegressor(n_estimators=5, random_state=0).fit(x_train, y_train)\n",
        "y_pred = tree.predict(x_test)\n",
        "round(mean_squared_error(y_test, y_pred) / 1000,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu-4AVFSl9xJ"
      },
      "source": [
        "8. Обучите на этих же данных случайный лес, используйте гиперпараметр `n_estimators = 100`, зафиксируйте  \n",
        "`random_state=0`. Оцените качество по метрике MSE на тестовой части. . Ответ разделите на 1000 и округлите до целой части по математичестким правилам округления."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "o03d3MNNl-5Z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(10.82)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree = RandomForestRegressor(n_estimators=100, random_state=0).fit(x_train, y_train)\n",
        "y_pred = tree.predict(x_test)\n",
        "round(mean_squared_error(y_test, y_pred) / 1000,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuC8uKXxmTAR"
      },
      "source": [
        "10. Изучите документацию и разберитесь как посчитать Out-of-bag ошибку в RandomForestRegressor. Обучите RandomForestRegressor с гиперпараметром n_estimators=100 на обучающей части, зафиксируйте  \n",
        "`random_state=0`. Найдите Out-of-bag ошибку алгоритма. Ответ округлите до сотых."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "6tj8UppYmUNH"
      },
      "outputs": [],
      "source": [
        "tree = RandomForestRegressor(n_estimators=100, random_state=0, oob_score=True).fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "round(1 - tree.oob_score_, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(11310.37)"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oob_predictions = tree.oob_prediction_\n",
        "\n",
        "oob_error = mean_squared_error(y_train, oob_predictions)\n",
        "round(oob_error, 2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
